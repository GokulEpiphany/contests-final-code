{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'data/hackerearth'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import models\n",
    "import torchvision\n",
    "\n",
    "\n",
    "def conv3x3(in_, out):\n",
    "    return nn.Conv2d(in_, out, 3, padding=1)\n",
    "\n",
    "\n",
    "class ConvRelu(nn.Module):\n",
    "    def __init__(self, in_, out):\n",
    "        super().__init__()\n",
    "        self.conv = conv3x3(in_, out)\n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class DecoderBlockV2(nn.Module):\n",
    "    def __init__(self, in_channels, middle_channels, out_channels, is_deconv=True):\n",
    "        super(DecoderBlockV2, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "        if is_deconv:\n",
    "            \"\"\"\n",
    "                Paramaters for Deconvolution were chosen to avoid artifacts, following\n",
    "                link https://distill.pub/2016/deconv-checkerboard/\n",
    "            \"\"\"\n",
    "\n",
    "            self.block = nn.Sequential(\n",
    "                ConvRelu(in_channels, middle_channels),\n",
    "                nn.ConvTranspose2d(middle_channels, out_channels, kernel_size=4, stride=2,\n",
    "                                   padding=1),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "        else:\n",
    "            self.block = nn.Sequential(\n",
    "                nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "                ConvRelu(in_channels, middle_channels),\n",
    "                ConvRelu(middle_channels, out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AxisNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=1, num_filters=32, pretrained=False, is_deconv=False):\n",
    "        \"\"\"\n",
    "        :param num_classes:\n",
    "        :param num_filters:\n",
    "        :param pretrained:\n",
    "            False - no pre-trained network is used\n",
    "            True  - encoder is pre-trained with resnet34\n",
    "        :is_deconv:\n",
    "            False: bilinear interpolation is used in decoder\n",
    "            True: deconvolution is used in decoder\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.encoder = torchvision.models.resnet34(pretrained=False)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv1 = nn.Sequential(self.encoder.conv1,\n",
    "                                   self.encoder.bn1,\n",
    "                                   self.encoder.relu,\n",
    "                                   self.pool)\n",
    "\n",
    "        self.conv2 = self.encoder.layer1\n",
    "\n",
    "        self.conv3 = self.encoder.layer2\n",
    "\n",
    "        self.conv4 = self.encoder.layer3\n",
    "\n",
    "        self.conv5 = self.encoder.layer4\n",
    "\n",
    "        self.center = DecoderBlockV2(512, num_filters * 8 * 2, num_filters * 8, is_deconv)\n",
    "\n",
    "        self.dec5 = DecoderBlockV2(512 + num_filters * 8, num_filters * 8 * 2, num_filters * 8, is_deconv)\n",
    "        self.dec4 = DecoderBlockV2(256 + num_filters * 8, num_filters * 8 * 2, num_filters * 8, is_deconv)\n",
    "        self.dec3 = DecoderBlockV2(128 + num_filters * 8, num_filters * 4 * 2, num_filters * 2, is_deconv)\n",
    "        self.dec2 = DecoderBlockV2(64 + num_filters * 2, num_filters * 2 * 2, num_filters * 2 * 2, is_deconv)\n",
    "        self.dec1 = DecoderBlockV2(num_filters * 2 * 2, num_filters * 2 * 2, num_filters, is_deconv)\n",
    "        self.dec0 = ConvRelu(num_filters, num_filters)\n",
    "        self.final = nn.Conv2d(num_filters, num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1 = self.conv1(x)\n",
    "        conv2 = self.conv2(conv1)\n",
    "        conv3 = self.conv3(conv2)\n",
    "        conv4 = self.conv4(conv3)\n",
    "        conv5 = self.conv5(conv4)\n",
    "\n",
    "        center = self.center(self.pool(conv5))\n",
    "\n",
    "        dec5 = self.dec5(torch.cat([center, conv5], 1))\n",
    "\n",
    "        dec4 = self.dec4(torch.cat([dec5, conv4], 1))\n",
    "        dec3 = self.dec3(torch.cat([dec4, conv3], 1))\n",
    "        dec2 = self.dec2(torch.cat([dec3, conv2], 1))\n",
    "        dec1 = self.dec1(dec2)\n",
    "        dec0 = self.dec0(dec1)\n",
    "\n",
    "        return F.sigmoid(self.final(dec0))\n",
    "    \n",
    "\n",
    "def axisnet(**kwargs):\n",
    "    model = AxisNet(**kwargs)\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_model():\n",
    "    model = axisnet()\n",
    "    model.train()\n",
    "    return model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from pathlib import Path\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path, mask = False):\n",
    "    \"\"\"\n",
    "    Load image from a given path and pad it on the sides, so that eash side is divisible by 32 (newtwork requirement)\n",
    "    \n",
    "    if pad = True:\n",
    "        returns image as numpy.array, tuple with padding in pixels as(x_min_pad, y_min_pad, x_max_pad, y_max_pad)\n",
    "    else:\n",
    "        returns image as numpy.array\n",
    "    \"\"\"\n",
    "    img = cv2.imread(str(path))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    height, width, _ = img.shape\n",
    "\n",
    "    # Padding in needed for UNet models because they need image size to be divisible by 32 \n",
    "    if height % 32 == 0:\n",
    "        y_min_pad = 0\n",
    "        y_max_pad = 0\n",
    "    else:\n",
    "        y_pad = 32 - height % 32\n",
    "        y_min_pad = int(y_pad / 2)\n",
    "        y_max_pad = y_pad - y_min_pad\n",
    "        \n",
    "    if width % 32 == 0:\n",
    "        x_min_pad = 0\n",
    "        x_max_pad = 0\n",
    "    else:\n",
    "        x_pad = 32 - width % 32\n",
    "        x_min_pad = int(x_pad / 2)\n",
    "        x_max_pad = x_pad - x_min_pad\n",
    "    \n",
    "    img = cv2.copyMakeBorder(img, y_min_pad, y_max_pad, x_min_pad, x_max_pad, cv2.BORDER_REFLECT_101)\n",
    "    if mask:\n",
    "        # Convert mask to 0 and 1 format\n",
    "        img = img[:, :, 0:1] // 255\n",
    "        return torch.from_numpy(img).float().permute([2, 0, 1])\n",
    "    else:\n",
    "        img = img / 255.0\n",
    "        return torch.from_numpy(img).float().permute([2, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from torch.utils import data\n",
    "\n",
    "class AxisDataset(data.Dataset):\n",
    "    def __init__(self, root_path, file_list, is_test = False):\n",
    "        self.is_test = is_test\n",
    "        self.root_path = root_path\n",
    "        self.file_list = file_list\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if index not in range(0, len(self.file_list)):\n",
    "            return self.__getitem__(np.random.randint(0, self.__len__()))\n",
    "        \n",
    "        file_id = self.file_list[index]\n",
    "        \n",
    "        image_folder = os.path.join(self.root_path, \"images\")\n",
    "        image_path = os.path.join(image_folder, file_id + \".png\")\n",
    "        \n",
    "        mask_folder = os.path.join(self.root_path, \"masks\")\n",
    "        mask_path = os.path.join(mask_folder, file_id + \".png\")\n",
    "        \n",
    "        image = load_image(image_path)\n",
    "        \n",
    "        if self.is_test:\n",
    "            return (image,)\n",
    "        else:\n",
    "            mask = load_image(mask_path, mask = True)\n",
    "            return image, mask\n",
    "\n",
    "train_path = os.path.join(directory, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    p = len(gt_sorted)\n",
    "    gts = gt_sorted.sum()\n",
    "    intersection = gts - gt_sorted.float().cumsum(0)\n",
    "    union = gts + (1 - gt_sorted).float().cumsum(0)\n",
    "    jaccard = 1. - intersection / union\n",
    "    if p > 1: # cover 1-pixel case\n",
    "        jaccard[1:p] = jaccard[1:p] - jaccard[0:-1]\n",
    "    return jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "    if len(labels) == 0:\n",
    "        # only void pixels, the gradients should be 0\n",
    "        return logits.sum() * 0.\n",
    "    signs = 2. * labels.float() - 1.\n",
    "    errors = (1. - logits * (signs))\n",
    "    errors_sorted, perm = torch.sort(errors, dim=0, descending=True)\n",
    "    perm = perm.data\n",
    "    gt_sorted = labels[perm]\n",
    "    grad = lovasz_grad(gt_sorted)\n",
    "    loss = torch.dot(F.relu(errors_sorted), (grad))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lovasz_hinge(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = scores.view(-1)\n",
    "    labels = labels.view(-1)\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = (labels != ignore)\n",
    "    vscores = scores[valid]\n",
    "    vlabels = labels[valid]\n",
    "    return vscores, vlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(l, ignore_nan=False, empty=0):\n",
    "    \"\"\"\n",
    "    nanmean compatible with generators.\n",
    "    \"\"\"\n",
    "    l = iter(l)\n",
    "    if ignore_nan:\n",
    "        l = ifilterfalse(np.isnan, l)\n",
    "    try:\n",
    "        n = 1\n",
    "        acc = next(l)\n",
    "    except StopIteration:\n",
    "        if empty == 'raise':\n",
    "            raise ValueError('Empty mean')\n",
    "        return empty\n",
    "    for n, v in enumerate(l, 2):\n",
    "        acc += v\n",
    "    if n == 1:\n",
    "        return acc\n",
    "    return acc / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = lovasz_hinge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "file_list_val = file_list[::10]\n",
    "file_list_train = [f for f in file_list if f not in file_list_val]\n",
    "dataset = TGSSaltDataset(train_path, file_list_train)\n",
    "dataset_val = TGSSaltDataset(train_path, file_list_val)\n",
    "\n",
    "model = get_model()\n",
    "#\n",
    "\n",
    "learning_rate = 1e-5\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(file_list_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(100):\n",
    "    train_loss = []\n",
    "    for image, mask in tqdm.tqdm(data.DataLoader(dataset, batch_size = 20, shuffle = True)):\n",
    "        image = image.type(torch.float).to(device)\n",
    "        y_pred = model(image)\n",
    "        logits = torch.log(y_pred/(1-y_pred))\n",
    "        loss = loss_fn(logits, mask.to(device))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.item())\n",
    "        \n",
    "    val_loss = []\n",
    "    for image, mask in data.DataLoader(dataset_val, batch_size = 16, shuffle = False):\n",
    "        image = image.to(device)\n",
    "        y_pred = model(image)\n",
    "        logits = torch.log(y_pred/(1-y_pred))\n",
    "        loss = loss_fn(logits, mask.to(device))\n",
    "        val_loss.append(loss.item())\n",
    "\n",
    "    print(\"Epoch: %d, Train: %.3f, Val: %.3f\" % (e, np.mean(train_loss), np.mean(val_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "test_path = os.path.join(directory, 'test')\n",
    "test_file_list = glob.glob(os.path.join(test_path, 'images', '*.png'))\n",
    "test_file_list = [f.split('\\\\')[-1].split('.')[0] for f in test_file_list]\n",
    "test_file_list[:3], test_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_file_list))\n",
    "test_dataset = TGSSaltDataset(test_path, test_file_list, is_test = True)\n",
    "\n",
    "all_predictions = []\n",
    "for image in tqdm.tqdm(data.DataLoader(test_dataset, batch_size = 30)):\n",
    "    image = image[0].type(torch.float).to(device)\n",
    "    y_pred = model(image).cpu().detach().numpy()\n",
    "    all_predictions.append(y_pred)\n",
    "all_predictions_stacked = np.vstack(all_predictions)[:, 0, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = 101, 101\n",
    "\n",
    "if height % 32 == 0:\n",
    "    y_min_pad = 0\n",
    "    y_max_pad = 0\n",
    "else:\n",
    "    y_pad = 32 - height % 32\n",
    "    y_min_pad = int(y_pad / 2)\n",
    "    y_max_pad = y_pad - y_min_pad\n",
    "\n",
    "if width % 32 == 0:\n",
    "    x_min_pad = 0\n",
    "    x_max_pad = 0\n",
    "else:\n",
    "    x_pad = 32 - width % 32\n",
    "    x_min_pad = int(x_pad / 2)\n",
    "    x_max_pad = x_pad - x_min_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions_stacked = all_predictions_stacked[:, y_min_pad:128 - y_max_pad, x_min_pad:128 - x_max_pad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions_stacked.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TGSSaltDataset(test_path, test_file_list, is_test = True)\n",
    "\n",
    "val_predictions = []\n",
    "val_masks = []\n",
    "for image, mask in tqdm.tqdm(data.DataLoader(dataset_val, batch_size = 30)):\n",
    "    image = image.type(torch.float).to(device)\n",
    "    y_pred = model(image).cpu().detach().numpy()\n",
    "    val_predictions.append(y_pred)\n",
    "    val_masks.append(mask)\n",
    "    \n",
    "val_predictions_stacked = np.vstack(val_predictions)[:, 0, :, :]\n",
    "\n",
    "val_masks_stacked = np.vstack(val_masks)[:, 0, :, :]\n",
    "val_predictions_stacked = val_predictions_stacked[:, y_min_pad:128 - y_max_pad, x_min_pad:128 - x_max_pad]\n",
    "\n",
    "val_masks_stacked = val_masks_stacked[:, y_min_pad:128 - y_max_pad, x_min_pad:128 - x_max_pad]\n",
    "val_masks_stacked.shape, val_predictions_stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_similarity_score\n",
    "\n",
    "metric_by_threshold = []\n",
    "for threshold in np.linspace(0, 1, 11):\n",
    "    val_binary_prediction = (val_predictions_stacked > threshold).astype(int)\n",
    "    \n",
    "    iou_values = []\n",
    "    for y_mask, p_mask in zip(val_masks_stacked, val_binary_prediction):\n",
    "        iou = jaccard_similarity_score(y_mask.flatten(), p_mask.flatten())\n",
    "        iou_values.append(iou)\n",
    "    iou_values = np.array(iou_values)\n",
    "    \n",
    "    accuracies = [\n",
    "        np.mean(iou_values > iou_threshold)\n",
    "        for iou_threshold in np.linspace(0.5, 0.95, 10)\n",
    "    ]\n",
    "    print('Threshold: %.1f, Metric: %.3f' % (threshold, np.mean(accuracies)))\n",
    "    metric_by_threshold.append((np.mean(accuracies), threshold))\n",
    "    \n",
    "best_metric, best_threshold = max(metric_by_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = best_threshold\n",
    "binary_prediction = (all_predictions_stacked > threshold).astype(int)\n",
    "\n",
    "def rle_encoding(x):\n",
    "    dots = np.where(x.T.flatten() == 1)[0]\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b > prev+1): run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return run_lengths\n",
    "\n",
    "all_masks = []\n",
    "for p_mask in list(binary_prediction):\n",
    "    p_mask = rle_encoding(p_mask)\n",
    "    all_masks.append(' '.join(map(str, p_mask)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame([test_file_list, all_masks]).T\n",
    "submit.columns = ['id', 'rle_mask']\n",
    "submit.to_csv('submit_baseline2.csv.gz', compression = 'gzip', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('resnet34.npy',binary_prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
